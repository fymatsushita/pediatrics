{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictive_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcvP284CETLCZN3914ZGar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fymatsushita/pediatrics/blob/main/Predictive_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLrTeS26YnPT"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lux\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curvey_scores = model.predict_proba(X_test)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from pprint import pprint\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnwE_b6tYv4v"
      },
      "source": [
        "df.head()\n",
        "df['Alert'] = df['Alert'].astype(float)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvbRwIkeY4zg"
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXB2Ul0TY6JH"
      },
      "source": [
        "p = df.hist(figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1WP4qM5Y-4L"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUlk8Z7RY_uq"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE02ZYGSZAfG"
      },
      "source": [
        "l = sns.pairplot(df, hue='Alert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28UhL428ZDud"
      },
      "source": [
        "# Grid search\n",
        "def GridSearchModel(X, y, model, parameters, cv):\n",
        "  CV_model = GridSearchCV(estimator=model, param_grid = parameters, cv = cv)\n",
        "  CV_model.fit(X,y)\n",
        "  CV_model.cv_results_\n",
        "  print(\"Best Score:\", CV_model.best_score_, \" / Best parameters:\", CV_model.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYZZQw4AZou2"
      },
      "source": [
        "# Learning curve\n",
        "def LearningCurve(X, y, model, cv, train_sizes):\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv = cv, n_jobs = 4, \n",
        "                                                            train_sizes = train_sizes)\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis = 1)\n",
        "    train_scores_std  = np.std(train_scores, axis = 1)\n",
        "    test_scores_mean  = np.mean(test_scores, axis = 1)\n",
        "    test_scores_std   = np.std(test_scores, axis = 1)\n",
        "    \n",
        "    train_Error_mean = np.mean(1- train_scores, axis = 1)\n",
        "    train_Error_std  = np.std(1 - train_scores, axis = 1)\n",
        "    test_Error_mean  = np.mean(1 - test_scores, axis = 1)\n",
        "    test_Error_std   = np.std(1 - test_scores, axis = 1)\n",
        "\n",
        "    Scores_mean = np.mean(train_scores_mean)\n",
        "    Scores_std = np.mean(train_scores_std)\n",
        "    \n",
        "    _, y_pred, Accuracy, Error, precision, recall, f1score = ApplyModel(X, y, model)\n",
        "    \n",
        "    plt.figure(figsize = (16,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    ax1 = Confuse(y, y_pred, classes)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.fill_between(train_sizes, train_Error_mean - train_Error_std,train_Error_mean + train_Error_std, alpha = 0.1,\n",
        "                     color = \"r\")\n",
        "    plt.fill_between(train_sizes, test_Error_mean - test_Error_std, test_Error_mean + test_Error_std, alpha = 0.1, color = \"g\")\n",
        "    plt.plot(train_sizes, train_Error_mean, 'o-', color = \"r\",label = \"Training Error\")\n",
        "    plt.plot(train_sizes, test_Error_mean, 'o-', color = \"g\",label = \"Cross-validation Error\")\n",
        "    plt.legend(loc = \"best\")\n",
        "    plt.grid(True)\n",
        "     \n",
        "    return (model, Scores_mean, Scores_std )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp9PkyiKZHm0"
      },
      "source": [
        "def ApplyModel(X, y, model):\n",
        "    \n",
        "    model.fit(X, y)\n",
        "    y_pred  = model.predict(X)\n",
        "\n",
        "    Accuracy = round(np.median(cross_val_score(model, X, y, cv = cv)),2)*100\n",
        " \n",
        "    Error   = 1 - Accuracy\n",
        "    \n",
        "    precision = precision_score(y_train, y_pred) * 100\n",
        "    recall = recall_score(y_train, y_pred) * 100\n",
        "    f1score = f1_score(y_train, y_pred) * 100\n",
        "    \n",
        "    return (model, y_pred, Accuracy, Error, precision, recall, f1score) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhcz-vIMZJcx"
      },
      "source": [
        "def Confuse(y, y_pred, classes):\n",
        "    cnf_matrix = confusion_matrix(y, y_pred)\n",
        "    \n",
        "    cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis = 1)[:, np.newaxis]\n",
        "    c_train = pd.DataFrame(cnf_matrix, index = classes, columns = classes)  \n",
        "\n",
        "    ax = sns.heatmap(c_train, annot = True, cmap = cmap, square = True, cbar = False, \n",
        "                          fmt = '.2f', annot_kws = {\"size\": 20})\n",
        "    return(ax, c_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zq_DQyyZK-V"
      },
      "source": [
        "def PrintResults(model, X, y, title):\n",
        "    \n",
        "    model, y_pred, Accuracy, Error, precision, recall, f1score = ApplyModel(X, y, model)\n",
        "    \n",
        "    _, Score_mean, Score_std = LearningCurve(X, y, model, cv, train_size)\n",
        "    Score_mean, Score_std = Score_mean*100, Score_std*100\n",
        "    \n",
        "    \n",
        "    print('Scoring Accuracy: %.2f %%'%(Accuracy))\n",
        "    print('Scoring Mean: %.2f %%'%(Score_mean))\n",
        "    print('Scoring Standard Deviation: %.4f %%'%(Score_std))\n",
        "    print(\"Precision: %.2f %%\"%(precision))\n",
        "    print(\"Recall: %.2f %%\"%(recall))\n",
        "    print('f1-score: %.2f %%'%(f1score))\n",
        "    \n",
        "    Summary = pd.DataFrame({'Model': title,\n",
        "                       'Accuracy': Accuracy, \n",
        "                       'Score Mean': Score_mean, \n",
        "                       'Score St Dv': Score_std, \n",
        "                       'Precision': precision, \n",
        "                       'Recall': recall, \n",
        "                       'F1-Score': f1score}, index = [0])\n",
        "    return (model, Summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROJLWcjDZM8Y"
      },
      "source": [
        "classes = ['0','1']\n",
        "cv = ShuffleSplit(n_splits = 100, test_size = 0.3, random_state = 0)\n",
        "train_size = np.linspace(.1, 1.0, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsaf0Zt-ZT1Q"
      },
      "source": [
        "X = df.drop(['Alert','Lactate_pH'],1)\n",
        "X2 = df.drop(['pCO2', 'pH', 'BIC', 'DOL','Alert', 'Lactate'], 1)\n",
        "X3 = df.drop(['Alert','Lactate','Lactate_pH'], 1)\n",
        "y = df['Alert']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.3, random_state=40, stratify=y)\n",
        "\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split (X_scaled, y, test_size=0.3, random_state=40, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY9L_8RuZcYH"
      },
      "source": [
        "cmap = sns.diverging_palette(220,10, as_cmap=True)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model, Summary_LR = PrintResults(model, X_train, y_train, 'Logistic Regression')\n",
        "\n",
        "y_train_LR = pd.Series(model.predict(X_train), name = \"LR\")\n",
        "y_test_LR = pd.Series(model.predict(X_test), name = \"LR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwEOuXfPZfY9"
      },
      "source": [
        "y_scores = model.predict_proba(X_test)\n",
        "y_scores = y_scores[:,1]\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "\n",
        "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
        "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
        "\n",
        "pred = model.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(y_test, pred, average='macro', sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pXdwr5OZ3UG"
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "params = {'n_estimators':[10,25,100],\n",
        "          'max_features':[5,8], # Number of max_features cannot be greater than the number of features\n",
        "          'max_depth':[10,50,None],\n",
        "          'bootstrap':[True,False]}\n",
        "\n",
        "clf = GridSearchCV(estimator=model,\n",
        "                   param_grid=params,\n",
        "                   scoring='accuracy',\n",
        "                   verbose=1)\n",
        "\n",
        "clf.fit(X,y)\n",
        "clf.best_estimator_\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Best F1: \", (-clf.best_score_))\n",
        "\n",
        "# Performance metrics\n",
        "grid_best = clf.best_estimator_.predict(X_train)\n",
        "errors = abs(grid_best - y_train)\n",
        "\n",
        "# Calculate mean absolute percentage error (MAPE)\n",
        "mape = np.mean(100 * (errors/y_train))\n",
        "\n",
        "# Calculate and display accuracy\n",
        "accuracy = 100 - mape\n",
        "\n",
        "print('The best model from grid-search has an accuracy of', round(accuracy, 2),'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68JnbrwfZ67B"
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(1, 45, num = 3)]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [5,10]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators':n_estimators,\n",
        "               'max_features':max_features,\n",
        "               'max_depth':max_depth,\n",
        "               'min_samples_split':min_samples_split}\n",
        "\n",
        "pprint(random_grid)\n",
        "\n",
        "# Random search of parameters, using 3 fold cross validation. Search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid,\n",
        "                               n_iter = 10, cv = 10, verbose = 2,\n",
        "                               random_state=42, n_jobs = -1, scoring='neg_mean_squared_error')\n",
        "\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "rf_random.best_estimator_\n",
        "\n",
        "random_best = rf_random.best_estimator_.predict(X_train)\n",
        "errors = abs(random_best - y_train)\n",
        "mape=np.mean(100*(errors/y_train))\n",
        "accuracy = 100 - mape\n",
        "print('The best model from the randomized search has an accuracy of', round(accuracy,2),'%')\n",
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AHIlEVXZ-qf"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators = 100, max_depth=50, bootstrap=True, max_features=6)\n",
        "model,Summary_RF = PrintResults(model, X_train, y_train, 'Random Forest')\n",
        "y_train_RF = pd.Series(model.predict(X_train), name=\"RF\")\n",
        "y_test_RF = pd.Series(model.predict(X_test), name = \"RF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71uia_b7aExQ"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators = 100, max_depth=None, bootstrap=True, max_features=6)\n",
        "model, y_pred, Accuracy, Error, precision, recall, f1score = ApplyModel(X_train, y_train, model)\n",
        "Priority = pd.DataFrame({'Feature': X_train.columns, 'Importance':np.round(model.feature_importances_,3)})\n",
        "Priority = Priority.sort_values('Importance',ascending=False).set_index('Feature')\n",
        "print(Priority)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usvq2R2taGhN"
      },
      "source": [
        "y_scores = model.predict_proba(X_test)\n",
        "y_scores = y_scores[:,1]\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "\n",
        "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
        "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
        "\n",
        "pred = model.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(y_test, pred, average='macro', sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkQ4uQqeaKjb"
      },
      "source": [
        "model = GaussianNB()\n",
        "model,Summary_GNB = PrintResults(model, X_train, y_train, \"GNB\")\n",
        "y_train_GNB = pd.Series(model.predict(X_train), name = \"GNB\")\n",
        "y_test_GNB = pd.Series(model.predict(X_test), name = \"GNB\")\n",
        "pred = model.predict_proba(X_test)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpzvaKX_aME-"
      },
      "source": [
        "y_scores = model.predict_proba(X_test)\n",
        "y_scores = y_scores[:,1]\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "\n",
        "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
        "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
        "\n",
        "pred = model.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(y_test, pred, average='macro', sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_v5di0YaRLQ"
      },
      "source": [
        "model = XGBClassifier()\n",
        "\n",
        "params = {\n",
        "          'max_depth': [3,5,7],\n",
        "          'eta': [0.01, 0.05, 0.1],\n",
        "          'n_estimators': [100, 500, 1000],\n",
        "          'colsample_bytree': [0.3, 0.7]}\n",
        "\n",
        "clf = GridSearchCV(estimator=model,\n",
        "                   param_grid=params,\n",
        "                   scoring='accuracy',\n",
        "                   verbose=1)\n",
        "\n",
        "clf.fit(X,y)\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Best F1: \", (-clf.best_score_))\n",
        "\n",
        "# Performance metrics\n",
        "grid_best = clf.best_estimator_.predict(X_train)\n",
        "errors = abs(grid_best - y_train)\n",
        "\n",
        "# Calculate mean absolute percentage error (MAPE)\n",
        "mape = np.mean(100 * (errors/y_train))\n",
        "\n",
        "# Calculate and display accuracy\n",
        "accuracy = 100 - mape\n",
        "\n",
        "print('The best model from grid-search has an accuracy of', round(accuracy, 2),'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8ECxkGQaTQG"
      },
      "source": [
        "params = {'max_depth':[3,5,6,8],\n",
        "          'learning_rate':[0.01,0.05,0.1,0.2],\n",
        "          'subsample':[0.4,1.0,0.1],\n",
        "          'colsample_bytree':[0.4,1.0,0.1],\n",
        "          'colsample_bylevel':[0.4,1.0,0.1],\n",
        "          'n_estimators':[100,500,1000]}\n",
        "  \n",
        "model = XGBClassifier()\n",
        "\n",
        "clf = RandomizedSearchCV(estimator=model,\n",
        "                         param_distributions = params,\n",
        "                         scoring='neg_mean_squared_error',\n",
        "                         n_iter=25,\n",
        "                         verbose=1)\n",
        "\n",
        "clf.fit(X,y)\n",
        "\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw3vwlyZaVE1"
      },
      "source": [
        "model = XGBClassifier(objective=\"binary:logistic\", eta=0.01, max_depth=6, min_child_weight=1, \n",
        "                      scale_pos_weight=1, gamma=0, colsample_bytree=1, nthread=4,\n",
        "                      early_stopping_round=5)\n",
        "model,Summary_XGB = PrintResults(model, X_train, y_train, 'XGB')\n",
        "y_train_XGB = pd.Series(model.predict(X_train), name = \"XGB\")\n",
        "y_test_XGB = pd.Series(model.predict(X_test), name = \"XGB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aaMrIEsaWu_"
      },
      "source": [
        "y_scores = model.predict_proba(X_test)\n",
        "y_scores = y_scores[:,1]\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "\n",
        "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
        "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
        "\n",
        "pred = model.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(y_test, pred, average='macro', sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xRrvCwUabc_"
      },
      "source": [
        "model = SVC()\n",
        "\n",
        "params = {'C':[0.1,1,10,100,1000],\n",
        "          'gamma':[1,0.1,0.01,0.001,0.0001],\n",
        "          'kernel':['rbf']}\n",
        "\n",
        "clf = GridSearchCV(SVC(),\n",
        "                   params,\n",
        "                   refit = True,\n",
        "                   verbose = 3)\n",
        "\n",
        "clf.fit(X,y)\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Best F1: \", (-clf.best_score_))\n",
        "print(clf.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESPVeGu5ac_w"
      },
      "source": [
        "model = SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
        "    probability=True, random_state=None, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "model, Summary_SVM = PrintResults(model, X_train_scaled, y_train_scaled, 'SVM')\n",
        "y_train_SVM = pd.Series(model.predict(X_train_scaled), name = \"SVM\")\n",
        "y_test_SVM = pd.Series(model.predict(X_test_scaled), name = 'SVM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YgysBZ3aemx"
      },
      "source": [
        "y_scores = model.predict_proba(X_test_scaled)\n",
        "y_scores = y_scores[:,1]\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "\n",
        "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
        "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
        "\n",
        "pred = model.predict_proba(X_test_scaled)[:,1]\n",
        "roc_auc_score(y_test, pred, average='macro', sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tm-XwpQak8S"
      },
      "source": [
        "model = KNeighborsClassifier()\n",
        "\n",
        "params = {'n_neighbors':[3,5,11,19],\n",
        "          'weights':['uniform','distance'],\n",
        "          'metric':['euclidean','manhattan']}\n",
        "\n",
        "clf = GridSearchCV(model,\n",
        "                   params,\n",
        "                   scoring='accuracy',\n",
        "                   verbose=1)\n",
        "\n",
        "clf.fit(X,y)\n",
        "clf.best_score_\n",
        "clf.best_estimator_\n",
        "clf.best_params_\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Best F1: \", (-clf.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aC_YRriam8o"
      },
      "source": [
        "model = KNeighborsClassifier(n_neighbors = 11, metric = 'manhattan', weights = 'uniform')\n",
        "model, Summary_KNN = PrintResults(model, X_train_scaled, y_train, 'KNN')\n",
        "y_train_KNN = pd.Series(model.predict(X_train_scaled), name = \"KNN\")\n",
        "y_test_KNN = pd.Series(model.predict(X_test_scaled), name=\"KNN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEr8fR6eaovv"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_scores = model.predict_proba(X_test_scaled)\n",
        "y_scores = y_scores[:,1]\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "\n",
        "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
        "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
        "\n",
        "pred = model.predict_proba(X_test_scaled)[:,1]\n",
        "roc_auc_score(y_test, pred, average='macro', sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}