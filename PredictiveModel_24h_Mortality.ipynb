{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictiveModel-24h_Mortality.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "M1I2F9kLhEOs",
        "R2RP9L9Ohsrz",
        "-CyfYh-syHaG",
        "vwlSOTO873Zz",
        "2N2Xv5QBokPE",
        "xyGDUsqdP3Qt"
      ],
      "mount_file_id": "19jkTfk9JeZ4PdfMtCYkAPjZ33LIS85_R",
      "authorship_tag": "ABX9TyNqvpejJdCBndO+vSvJ7DMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fymatsushita/pediatrics/blob/main/PredictiveModel_24h_Mortality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NS_eesahg_9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lux"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBTFeilTijM0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3DbUuZcjObT"
      },
      "source": [
        "df['Alert'] = df['Alert'].astype(float)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yawzyZojV0W"
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JvCtGKHlCMv"
      },
      "source": [
        "p = df.hist(figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQTLYO8JlLvP"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjGj5BFSlYRf"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPojNs1gljj-"
      },
      "source": [
        "l = sns.pairplot(df, hue='Alert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhGx_GVtyemf"
      },
      "source": [
        "X_train = df.loc[:,df.columns != 'Alert']\n",
        "y_train = df['Alert']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtGvQqTBy_Mt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "fef9eede-642f-49bf-f239-6ba9f856e945"
      },
      "source": [
        "from BorutaShap import BorutaShap\n",
        "\n",
        "feature_selector = BorutaShap(importance_measure='shap', classification=False)\n",
        "feature_selector.fit(X=X_train, y=y_train, n_trials=50, random_state=0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0b4a3105633c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBorutaShap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBorutaShap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBorutaShap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_measure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'shap'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'BorutaShap'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Ak66nH7Jqn"
      },
      "source": [
        "feature_selector.plot(which_features='all', figsize=(16,12))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTXD3tyc754M"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.loc[:,df.columns != 'Alert']\n",
        "y = df['Alert']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSF5GjFU9nkc"
      },
      "source": [
        "model_xgb = XGBClassifier()\n",
        "model_xgb.fit(train_X, train_y, verbose=False)\n",
        "xgb.plot_importance(model_xgb, max_num_features=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBMOrxGK97IY"
      },
      "source": [
        "pred_xgb = model_xgb.predict(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3It63EPor_V"
      },
      "source": [
        "# Grid search\n",
        "def GridSearchModel(X, y, model, parameters, cv):\n",
        "  CV_model = GridSearchCV(estimator=model, param_grid = parameters, cv = cv)\n",
        "  CV_model.fit(X,y)\n",
        "  CV_model.cv_results_\n",
        "  print(\"Best Score:\", CV_model.best_score_, \" / Best parameters:\", CV_model.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLETDZ5xpHVG"
      },
      "source": [
        "# Learning curve\n",
        "def LearningCurve(X, y, model, cv, train_sizes):\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv = cv, n_jobs = 4, \n",
        "                                                            train_sizes = train_sizes)\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis = 1)\n",
        "    train_scores_std  = np.std(train_scores, axis = 1)\n",
        "    test_scores_mean  = np.mean(test_scores, axis = 1)\n",
        "    test_scores_std   = np.std(test_scores, axis = 1)\n",
        "    \n",
        "    train_Error_mean = np.mean(1- train_scores, axis = 1)\n",
        "    train_Error_std  = np.std(1 - train_scores, axis = 1)\n",
        "    test_Error_mean  = np.mean(1 - test_scores, axis = 1)\n",
        "    test_Error_std   = np.std(1 - test_scores, axis = 1)\n",
        "\n",
        "    Scores_mean = np.mean(train_scores_mean)\n",
        "    Scores_std = np.mean(train_scores_std)\n",
        "    \n",
        "    _, y_pred, Accuracy, Error, precision, recall, f1score = ApplyModel(X, y, model)\n",
        "    \n",
        "    plt.figure(figsize = (16,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    ax1 = Confuse(y, y_pred, classes)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.fill_between(train_sizes, train_Error_mean - train_Error_std,train_Error_mean + train_Error_std, alpha = 0.1,\n",
        "                     color = \"r\")\n",
        "    plt.fill_between(train_sizes, test_Error_mean - test_Error_std, test_Error_mean + test_Error_std, alpha = 0.1, color = \"g\")\n",
        "    plt.plot(train_sizes, train_Error_mean, 'o-', color = \"r\",label = \"Training Error\")\n",
        "    plt.plot(train_sizes, test_Error_mean, 'o-', color = \"g\",label = \"Cross-validation Error\")\n",
        "    plt.legend(loc = \"best\")\n",
        "    plt.grid(True)\n",
        "     \n",
        "    return (model, Scores_mean, Scores_std )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlox4G0hpti5"
      },
      "source": [
        "def ApplyModel(X, y, model):\n",
        "    \n",
        "    model.fit(X, y)\n",
        "    y_pred  = model.predict(X)\n",
        "\n",
        "    Accuracy = round(np.median(cross_val_score(model, X, y, cv = cv)),2)*100\n",
        " \n",
        "    Error   = 1 - Accuracy\n",
        "    \n",
        "    precision = precision_score(y_train, y_pred) * 100\n",
        "    recall = recall_score(y_train, y_pred) * 100\n",
        "    f1score = f1_score(y_train, y_pred) * 100\n",
        "    \n",
        "    return (model, y_pred, Accuracy, Error, precision, recall, f1score) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7UgN--RpxTv"
      },
      "source": [
        "def Confuse(y, y_pred, classes):\n",
        "    cnf_matrix = confusion_matrix(y, y_pred)\n",
        "    \n",
        "    cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis = 1)[:, np.newaxis]\n",
        "    c_train = pd.DataFrame(cnf_matrix, index = classes, columns = classes)  \n",
        "\n",
        "    ax = sns.heatmap(c_train, annot = True, cmap = cmap, square = True, cbar = False, \n",
        "                          fmt = '.2f', annot_kws = {\"size\": 20})\n",
        "    return(ax, c_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFM_lafKpztM"
      },
      "source": [
        "def PrintResults(model, X, y, title):\n",
        "    \n",
        "    model, y_pred, Accuracy, Error, precision, recall, f1score = ApplyModel(X, y, model)\n",
        "    \n",
        "    _, Score_mean, Score_std = LearningCurve(X, y, model, cv, train_size)\n",
        "    Score_mean, Score_std = Score_mean*100, Score_std*100\n",
        "    \n",
        "    \n",
        "    print('Scoring Accuracy: %.2f %%'%(Accuracy))\n",
        "    print('Scoring Mean: %.2f %%'%(Score_mean))\n",
        "    print('Scoring Standard Deviation: %.4f %%'%(Score_std))\n",
        "    print(\"Precision: %.2f %%\"%(precision))\n",
        "    print(\"Recall: %.2f %%\"%(recall))\n",
        "    print('f1-score: %.2f %%'%(f1score))\n",
        "    \n",
        "    Summary = pd.DataFrame({'Model': title,\n",
        "                       'Accuracy': Accuracy, \n",
        "                       'Score Mean': Score_mean, \n",
        "                       'Score St Dv': Score_std, \n",
        "                       'Precision': precision, \n",
        "                       'Recall': recall, \n",
        "                       'F1-Score': f1score}, index = [0])\n",
        "    return (model, Summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R0RuBXnp9A_"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "classes = ['0','1']\n",
        "cv = ShuffleSplit(n_splits = 100, test_size = 0.3, random_state = 0)\n",
        "train_size = np.linspace(.1, 1.0, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b_3xTMwsG6O"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X = df.drop(['pCO2', 'pH', 'BIC', 'DOL','Alert', 'Lactate','BE','cGA'], 1)\n",
        "X2 = df.drop(['Alert'], 1)\n",
        "y = df['Alert']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.3, random_state=40, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fOEpl6VqNib"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cmap = sns.diverging_palette(220,10, as_cmap=True)\n",
        "model = LogisticRegression()\n",
        "model, Summary_LR = PrintResults(model, X_train, y_train, 'Logistic Regression')\n",
        "\n",
        "y_train_LR = pd.Series(model.predict(X_train), name = \"LR\")\n",
        "y_test_LR = pd.Series(model.predict(X_test), name = \"LR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y5H3GRtvUbT"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "%timeit\n",
        "model = RandomForestClassifier(n_estimators = 200)\n",
        "model,Summary_RF = PrintResults(model, X_train, y_train, 'Random Forest')\n",
        "y_train_RF = pd.Series(model.predict(X_train), name=\"RF\")\n",
        "y_test_RF = pd.Series(model.predict(X_test), name = \"RF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jps87AcK7Ax"
      },
      "source": [
        "model, y_pred, Accuracy, Error, precision, recall, f1score = ApplyModel(X_train, y_train, model)\n",
        "Priority = pd.DataFrame({'Feature': X_train.columns, 'Importance':np.round(model.feature_importances_,3)})\n",
        "Priority = Priority.sort_values('Importance',ascending=False).set_index('Feature')\n",
        "print(Priority)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgC58CRHv0JB"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split (X_scaled, y, test_size=0.3, random_state=40, stratify=y)\n",
        "\n",
        "model = SVC()\n",
        "model, Summary_SVM = PrintResults(model, X_train_scaled, y_train_scaled, 'SVM')\n",
        "y_train_SVM = pd.Series(model.predict(X_train_scaled), name = \"SVM\")\n",
        "y_test_SVM = pd.Series(model.predict(X_test_scaled), name = 'SVM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFBzcUr2xizv"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "model = LinearSVC()\n",
        "model,Summary_LSVM = PrintResults(model, X_train_scaled, y_train,\"LSVM\")\n",
        "y_train_LSVM = pd.Series(model.predict(X_train_scaled), name = \"LSVM\")\n",
        "y_test_LSVM = pd.Series(model.predict(X_test_scaled), name = \"LSVM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZgnJPMuumKD"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "model = SGDClassifier(max_iter = 200, tol = None)\n",
        "model, Summary_SGD = PrintResults(model, X_train_scaled, y_train, 'SGD')\n",
        "y_train_SGD = pd.Series(model.predict(X_train_scaled), name = \"SGD\")\n",
        "y_test_SGD = pd.Series(model.predict(X_test_scaled), name= 'SGD')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqB-pzURwiup"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors = 3)\n",
        "model, Summary_KNN = PrintResults(model, X_train_scaled, y_train, 'KNN')\n",
        "y_train_KNN = pd.Series(model.predict(X_train_scaled), name = \"KNN\")\n",
        "y_test_KNN = pd.Series(model.predict(X_test_scaled), name=\"KNN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61DYuKVmxLM-"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model,Summary_GNB = PrintResults(model, X_train, y_train, \"GNB\")\n",
        "y_train_GNB = pd.Series(model.predict(X_train), name = \"GNB\")\n",
        "y_test_GNB = pd.Series(model.predict(X_test), name = \"GNB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYl8GJblxXex"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "model = Perceptron(max_iter = 5)\n",
        "model,Summary_MLP = PrintResults(model, X_train_scaled, y_train, 'MLP')\n",
        "y_train_MLP = pd.Series(model.predict(X_train_scaled), name = \"MLP\")\n",
        "y_test_MLP = pd.Series(model.predict(X_test_scaled), name = \"MLP\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PforlPkAywyo"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(objective=\"binary:logistic\", eta=0.01, max_depth=6, min_child_weight=1, \n",
        "                      scale_pos_weight=1, gamma=0, colsample_bytree=0.9, nthread=4,\n",
        "                      early_stopping_round=5)\n",
        "model,Summary_XGB = PrintResults(model, X_train, y_train, 'XGB')\n",
        "y_train_XGB = pd.Series(model.predict(X_train), name = \"XGB\")\n",
        "y_test_XGB = pd.Series(model.predict(X_test), name = \"XGB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtoIVPcXx-Or"
      },
      "source": [
        "Class_Results = pd.concat([Summary_LR, Summary_SGD, Summary_RF, \n",
        "                           Summary_SVM, Summary_KNN, Summary_GNB,\n",
        "                           Summary_MLP, Summary_LSVM, Summary_XGB], ignore_index = True)\n",
        "    \n",
        "\n",
        "Class_Results = Class_Results.sort_values(by = 'F1-Score', ascending=False)\n",
        "Class_Results = Class_Results.set_index('F1-Score')\n",
        "print(Class_Results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_tTa8ljDkad"
      },
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Add the models to the list that you want to view on the ROC plot\n",
        "models = [\n",
        "{\n",
        "    'label': 'Logistic Regression',\n",
        "    'model': LogisticRegression(),\n",
        "},\n",
        "{\n",
        "    'label': 'Random Forest',\n",
        "    'model': RandomForestClassifier(),\n",
        "},\n",
        "{\n",
        "    'label': 'XGBoost',\n",
        "    'model': XGBClassifier()\n",
        "},\n",
        "{\n",
        "    'label': 'Gaussian Naive Bayes',\n",
        "    'model': GaussianNB()\n",
        "}\n",
        "]\n",
        "\n",
        "# Below for loop iterates through your models list\n",
        "for m in models:\n",
        "    model = m['model'] # select the model\n",
        "    model.fit(X_train, y_train) # train the model\n",
        "    y_pred=model.predict(X_test) # predict the test data\n",
        "\n",
        "# Compute False postive rate, and True positive rate\n",
        "    pred = model.predict_proba(X_test)[:,1]\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
        "# Calculate Area under the curve to display on the plot\n",
        "    auc = metrics.roc_auc_score(y_test,pred)\n",
        "# Now, plot the computed values\n",
        "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], auc))\n",
        "# Custom settings for the plot \n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('1-Specificity(False Positive Rate)')\n",
        "plt.ylabel('Sensitivity(True Positive Rate)')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()   # Display"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}